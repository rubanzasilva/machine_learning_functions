{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHiQ/BSTj1pV/TtpCr7/1o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rubanzasilva/machine_learning_functions/blob/main/cross_validation_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "%pip install catboost\n",
        "%pip install optuna\n",
        "#%pip install optuna_distributed\n",
        "#%pip install openfe\n",
        "%pip install seaborn\n",
        "%pip install xgboost\n",
        "%pip install lightgbm\n",
        "%pip install fastkaggle\n",
        "#%pip install h2o\n",
        "%pip install -Uqq fastbook\n",
        "#%pip install polars\n",
        "%pip install -q -U autogluon.tabular\n",
        "%pip install autogluon\n",
        "%pip install --upgrade pip\n",
        "%pip install tqdm\n",
        "#%pip install wandb\n",
        "#%pip install sweetviz"
      ],
      "metadata": {
        "id": "w9U75s88peew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "#import fastbook\n",
        "#fastbook.setup_book()\n",
        "#from fastbook import *\n",
        "from fastai.tabular.all import *\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "from tqdm import tqdm\n",
        "from ipywidgets import interact\n",
        "\n",
        "from fastai.imports import *\n",
        "np.set_printoptions(linewidth=130)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.metrics import root_mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import VotingClassifier,StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold,StratifiedKFold, cross_val_score,train_test_split,GridSearchCV\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from catboost import CatBoostClassifier,CatBoostRegressor,Pool, metrics, cv\n",
        "\n",
        "\n",
        "import warnings\n",
        "\n",
        "\n",
        "#from openfe import OpenFE, transform\n",
        "#from autogluon.tabular import TabularDataset, TabularPredictor\n",
        "\n",
        "#import h2o\n",
        "#from h2o.automl import H2OAutoML\n",
        "\n",
        "import gc\n",
        "\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "import pickle\n",
        "from joblib import dump, load\n",
        "#import sweetviz as sv\n",
        "#from IPython.display import FileLink\n",
        "\n",
        "#import h2o\n",
        "#from h2o.automl import H2OAutoML"
      ],
      "metadata": {
        "id": "TXEbM0bcpeIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oBIqdHoMpnZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "thvtt1-YpPNP",
        "outputId": "6fafb098-cd6f-45d9-a829-ebc63547617d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e754754f7676>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msub_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moriginal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/depression-surveydataset-for-analysis/final_depression_dataset_1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(path/'train.csv',index_col='id')\n",
        "test_df = pd.read_csv(path/'test.csv',index_col='id')\n",
        "sub_df = pd.read_csv(path/'sample_submission.csv')\n",
        "original_df = pd.read_csv('/kaggle/input/depression-surveydataset-for-analysis/final_depression_dataset_1.csv')\n",
        "\n",
        "cont_names,cat_names = cont_cat_split(train_df, dep_var='Depression')\n",
        "splits = RandomSplitter(valid_pct=0.2)(range_of(train_df))\n",
        "to = TabularPandas(train_df, procs=[Categorify, FillMissing,Normalize],\n",
        "#to = TabularPandas(train_df, procs=[Categorify,Normalize],\n",
        "                   cat_names = cat_names,\n",
        "                   cont_names = cont_names,\n",
        "                   y_names='Depression',\n",
        "                   y_block=CategoryBlock(),\n",
        "                   splits=splits)\n",
        "dls = to.dataloaders(bs=64)\n",
        "#dls = to.dataloaders(bs=1024)\n",
        "test_dl = dls.test_dl(test_df)\n",
        "\n",
        "X_train, y_train = to.train.xs, to.train.ys.values.ravel()\n",
        "X_test, y_test = to.valid.xs, to.valid.ys.values.ravel()\n",
        "\n",
        "def cross_val_predict(model_class, model_params=None, n_splits=5, random_state=42):\n",
        "    if model_params is None:\n",
        "        model_params = {}\n",
        "    \"\"\"\n",
        "    Perform cross-validation using the fixed dataset and return predictions and scores.\n",
        "\n",
        "    Parameters:\n",
        "    - model_class: the model class (e.g., xgb.XGBClassifier)\n",
        "    - model_params: dictionary of model parameters\n",
        "    - n_splits: number of CV folds\n",
        "    - random_state: random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    - oof_predictions: out-of-fold predictions on training set\n",
        "    - submission_predictions: predictions on test_dl.xs\n",
        "    - mean_score: mean accuracy score across folds\n",
        "    - fold_scores: list of scores for each fold\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize stratified k-fold\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    # Initialize arrays to store results\n",
        "    oof_predictions = np.zeros(len(X_train))  # Array for OOF predictions\n",
        "    submission_predictions = np.zeros(len(test_dl.xs))  # Array for test predictions\n",
        "    fold_scores = []\n",
        "\n",
        "    # Perform cross-validation\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train), 1):\n",
        "        # Split data for current fold\n",
        "        X_fold_train, X_fold_val = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
        "\n",
        "        # Initialize and train model on current fold\n",
        "        model_fold = model_class(**model_params)\n",
        "        model_fold.fit(X_fold_train, y_fold_train)\n",
        "\n",
        "        # Get predictions\n",
        "        y_pred_fold = model_fold.predict(X_fold_val)\n",
        "\n",
        "        # Store OOF predictions\n",
        "        oof_predictions[val_index] = y_pred_fold\n",
        "\n",
        "        # Get and accumulate test predictions\n",
        "        submission_predictions += model_fold.predict(test_dl.xs) / n_splits\n",
        "\n",
        "        # Calculate and store score\n",
        "        cv_score = accuracy_score(y_fold_val, y_pred_fold)\n",
        "        fold_scores.append(cv_score)\n",
        "\n",
        "        print(f\"Fold {fold} AUC: {cv_score:.6f}\")\n",
        "\n",
        "    # Calculate mean score\n",
        "    mean_score = np.mean(fold_scores)\n",
        "    print(f\"\\nMean AUC: {mean_score:.6f}\")\n",
        "\n",
        "    return oof_predictions, submission_predictions, mean_score, fold_scores\n",
        "\n",
        "# Usage example:\n",
        "#oof_preds, submission_preds, mean_score, fold_scores = cross_val_predict(\n",
        "    #model_class=xgb.XGBClassifier\n",
        "#)\n",
        "\n",
        "# Create submission file\n",
        "#submission_df = pd.DataFrame({\n",
        "    #'id': test_df.index,  # adjust if you have different id column\n",
        "    #'Depression': submission_preds\n",
        "#})\n",
        "#submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "# You can also analyze OOF predictions\n",
        "#print(\"\\nOOF Predictions Score:\", accuracy_score(y_train, oof_preds))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BzRmSgicpuRJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}